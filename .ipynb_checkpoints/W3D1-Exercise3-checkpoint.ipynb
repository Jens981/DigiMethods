{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3: Functions and Data\n",
    "\n",
    "Builds on exercises provided by programminghistorian.org. \n",
    "\n",
    "## 3.1 Functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.1.1**: Write a function `is_number` that uses the `try` and `except` structure to return `True` of the input is a number, or print a relevant error statement and returns `None` if the input is not a number. Test your function on several cases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "def is_number(tal):\n",
    "        try:\n",
    "            values = float(tal)\n",
    "        except ValueError:\n",
    "            print(\"List consist of items that cannot be calculated\")\n",
    "            return None\n",
    "        else: \n",
    "            print(True)\n",
    "        \n",
    "is_number(100)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.1.2**: Write some test cases for your function. Did you have to change your function based on your test cases? If so, explain. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "is_number(19.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.1.3**: Write a function `word_freq` that takes in a list of words and counts the frequency of each word in the list. Your function should return a dictionary with the word as the key and the count as the value. \n",
    "\n",
    "Hint: Useful string methods to look at is `count()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 2, 3: 2, 4: 2, 5: 2, 6: 2, 7: 2}\n"
     ]
    }
   ],
   "source": [
    "liste2 = [1, 3, 5, 6, 7, 5, 4, 3, 1, 4, 6, 7, 5 ]\n",
    "\n",
    "def word_freq(lst_to_dict):\n",
    "    print(dict( (l, lst_to_dict.count(1) ) for l in set(lst_to_dict)))\n",
    "    return\n",
    "\n",
    "word_freq(liste2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 2, 3: 2, 4: 2, 5: 3, 6: 2, 7: 2}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def word_freq2(list):\n",
    "    dict9 = {}\n",
    "\n",
    "    list = sorted(list)\n",
    "    for w in list:\n",
    "        \n",
    "            dict9[w] = list.count(w)\n",
    "        \n",
    "        \n",
    "    return(dict9)\n",
    "\n",
    "word_freq2(liste2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 2, 2: 3, 3: 4, 5: 1, 6: 1, 4: 3}\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "liste3 = [1, 2, 3, 3, 3, 5, 6, 4, 4, 4, 2, 1, 2, 3]\n",
    "c = Counter(liste3)\n",
    "\n",
    "c = dict(c)\n",
    "\n",
    "print(c)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.1.4**: Write a function  `sort_freq_dict` that takes a dictionary of key value pairs that are words and their frequencies. The function should turn the dictionary into a list of (freq, word) tuples, sorted highest to lowest by frequency. The function should return this list. \n",
    "\n",
    "Hint: list methods `sort()` and `reverse()` will be useful. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(12, 'Kim'), (25, 'Simon'), (27, 'Lars'), (27, 'Mike'), (69, 'Ole')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ages = {\"Kim\": 12, \"Simon\": 25, \"Lars\": 27, \"Ole\": 69, \"Mike\": 27}\n",
    "\n",
    "def sort_freq_dict(dicts):\n",
    "    lst = zip(dicts.values(), dicts.keys())\n",
    "    lst = list(lst)\n",
    "    return(sorted(lst))\n",
    "\n",
    "objekt = sort_freq_dict(ages)\n",
    "\n",
    "print(objekt)\n",
    "\n",
    "type(objekt[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.1.5**: Write a function called `remove_stop_words` that takes two lists of words as input (a word list and a stop word list). Your function should return a list of words with all the words in the word list except those found in the stop word list. \n",
    "\n",
    "Note: A stop word list is a list of common words (e.g. the, a, and, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This', 'list', 'strings', 'go', 'function']"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liste_af_strings = [\"This\", \"is\", \"a\", \"list\", \"of\", \"strings\", \"that\", \"should\", \"go\", \"into\", \"function\"]\n",
    "\n",
    "\n",
    "def remove_stop_words(liste):\n",
    "    filtered_words = [word for word in liste if word not in stopwords.words('english')]\n",
    "    return(filtered_words)\n",
    "\n",
    "remove_stop_words(liste_af_strings)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Text Files\n",
    "\n",
    "**Question 2.2.1**: Read in the text files `stop_words.txt` and turn it into a list of words. \n",
    "\n",
    "Note: when you look at the file you see that each word is on a different line. Remember to remove the newline characters for each line/word.\n",
    "\n",
    "Stopwords from: http://ir.dcs.gla.ac.uk/resources/linguistic_utils/stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def read_words(filename):\n",
    "    import re\n",
    "    \n",
    "    word_pattern = \"(\\S)\"\n",
    "    \n",
    "    file = open(filename, \"r\")\n",
    "    file = filt.split(\",\")\n",
    "\n",
    "    words = []\n",
    "\n",
    "    for line in file:\n",
    "        temp_words = re.search(word_pattern, line)\n",
    "    \n",
    "    if temp_words:\n",
    "        words.append(temp_words.group())\n",
    "        \n",
    "    file.close()\n",
    "    \n",
    "    \n",
    "\n",
    "    print(words)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stop_words' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-359-1aee65479dff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mreturn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mfks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstop_words\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtxt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'stop_words' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "words2 = []\n",
    "\n",
    "def fks(fil):\n",
    "    file = open(\"fil\", \"r\")\n",
    "    words = list(file.read().split)\n",
    "    return(words)\n",
    "\n",
    "fks(stop_words.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'about', 'above', 'across', 'after', 'afterwards', 'again', 'against', 'all', 'almost', 'alone', 'along', 'already', 'also', 'although', 'always', 'am', 'among', 'amongst', 'amoungst', 'amount', 'an', 'and', 'another', 'any', 'anyhow', 'anyone', 'anything', 'anyway', 'anywhere', 'are', 'around', 'as', 'at', 'back', 'be', 'became', 'because', 'become', 'becomes', 'becoming', 'been', 'before', 'beforehand', 'behind', 'being', 'below', 'beside', 'besides', 'between', 'beyond', 'bill', 'both', 'bottom', 'but', 'by', 'call', 'can', 'cannot', 'cant', 'co', 'computer', 'con', 'could', 'couldnt', 'cry', 'de', 'describe', 'detail', 'do', 'done', 'down', 'due', 'during', 'each', 'eg', 'eight', 'either', 'eleven', 'else', 'elsewhere', 'empty', 'enough', 'etc', 'even', 'ever', 'every', 'everyone', 'everything', 'everywhere', 'except', 'few', 'fifteen', 'fify', 'fill', 'find', 'fire', 'first', 'five', 'for', 'former', 'formerly', 'forty', 'found', 'four', 'from', 'front', 'full', 'further', 'get', 'give', 'go', 'had', 'has', 'hasnt', 'have', 'he', 'hence', 'her', 'here', 'hereafter', 'hereby', 'herein', 'hereupon', 'hers', 'herself', 'him', 'himself', 'his', 'how', 'however', 'hundred', 'i', 'ie', 'if', 'in', 'inc', 'indeed', 'interest', 'into', 'is', 'it', 'its', 'itself', 'keep', 'last', 'latter', 'latterly', 'least', 'less', 'ltd', 'made', 'many', 'may', 'me', 'meanwhile', 'might', 'mill', 'mine', 'more', 'moreover', 'most', 'mostly', 'move', 'much', 'must', 'my', 'myself', 'name', 'namely', 'neither', 'never', 'nevertheless', 'next', 'nine', 'no', 'nobody', 'none', 'noone', 'nor', 'not', 'nothing', 'now', 'nowhere', 'of', 'off', 'often', 'on', 'once', 'one', 'only', 'onto', 'or', 'other', 'others', 'otherwise', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 'part', 'per', 'perhaps', 'please', 'put', 'rather', 're', 'same', 'see', 'seem', 'seemed', 'seeming', 'seems', 'serious', 'several', 'she', 'should', 'show', 'side', 'since', 'sincere', 'six', 'sixty', 'so', 'some', 'somehow', 'someone', 'something', 'sometime', 'sometimes', 'somewhere', 'still', 'such', 'system', 'take', 'ten', 'than', 'that', 'the', 'their', 'them', 'themselves', 'then', 'thence', 'there', 'thereafter', 'thereby', 'therefore', 'therein', 'thereupon', 'these', 'they', 'thick', 'thin', 'third', 'this', 'those', 'though', 'three', 'through', 'throughout', 'thru', 'thus', 'to', 'together', 'too', 'top', 'toward', 'towards', 'twelve', 'twenty', 'two', 'un', 'under', 'until', 'up', 'upon', 'us', 'very', 'via', 'was', 'we', 'well', 'were', 'what', 'whatever', 'when', 'whence', 'whenever', 'where', 'whereafter', 'whereas', 'whereby', 'wherein', 'whereupon', 'wherever', 'whether', 'which', 'while', 'whither', 'who', 'whoever', 'whole', 'whom', 'whose', 'why', 'will', 'with', 'within', 'without', 'would', 'yet', 'you', 'your', 'yours', 'yourself', 'yourselves']\n"
     ]
    }
   ],
   "source": [
    "file = open(\"stop_words.txt\", 'r')\n",
    "words = list(file.read().split())\n",
    "print(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-448-310ee819d730>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'[^a-z\\ \\']+'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\" \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\re.py\u001b[0m in \u001b[0;36msub\u001b[1;34m(pattern, repl, string, count, flags)\u001b[0m\n\u001b[0;32m    190\u001b[0m     \u001b[0ma\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mit\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mMatch\u001b[0m \u001b[0mobject\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mmust\u001b[0m \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m     a replacement string to be used.\"\"\"\n\u001b[1;32m--> 192\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msubn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrepl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "file = open(\"stop_words.txt\", \"r\")\n",
    "text = file.read()\n",
    "file.close()\n",
    "text = re.sub('[^a-z\\ \\']+', \" \", text) \n",
    "words = list(text.split())\n",
    "print(words)\n",
    "\n",
    "\n",
    "    \n",
    "        \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.2.2**: Write a function `make_wordlist` that takes a filename as the argument. The function reads the file, turning the text to lower case and removes all non alpha-numeric characters. The function returns a list of all the words.  \n",
    "\n",
    "Hint: You will need to use a regular expression for only alphanumeric characters. Use `search(pattern, text)` and `group()` methods following the example in class.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'ACROSS',\n",
       " 'after',\n",
       " 'afterwards',\n",
       " 'again',\n",
       " 'against',\n",
       " 'all',\n",
       " 'almost',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'already',\n",
       " 'also',\n",
       " 'although',\n",
       " 'always',\n",
       " 'am',\n",
       " 'among',\n",
       " 'amongst',\n",
       " 'amoungst',\n",
       " 'amount',\n",
       " 'an',\n",
       " 'and',\n",
       " 'another',\n",
       " 'any',\n",
       " 'anyhow',\n",
       " 'anyone',\n",
       " 'anything',\n",
       " 'anyway',\n",
       " 'anywhere',\n",
       " 'are',\n",
       " 'around',\n",
       " 'as',\n",
       " 'at',\n",
       " 'back',\n",
       " 'be',\n",
       " 'became',\n",
       " 'because',\n",
       " 'become',\n",
       " 'becomes',\n",
       " 'becoming',\n",
       " 'been',\n",
       " 'before',\n",
       " 'beforehand',\n",
       " 'behind',\n",
       " 'being',\n",
       " 'below',\n",
       " 'beside',\n",
       " 'besides',\n",
       " 'between',\n",
       " 'beyond',\n",
       " 'bill',\n",
       " 'both',\n",
       " 'bottom',\n",
       " 'but',\n",
       " 'by',\n",
       " 'call',\n",
       " 'can',\n",
       " 'cannot',\n",
       " 'cant',\n",
       " 'co',\n",
       " 'computer',\n",
       " 'con',\n",
       " 'could',\n",
       " 'couldnt',\n",
       " 'cry',\n",
       " 'de',\n",
       " 'describe',\n",
       " 'detail',\n",
       " 'do',\n",
       " 'done',\n",
       " 'down',\n",
       " 'due',\n",
       " 'during',\n",
       " 'each',\n",
       " 'eg',\n",
       " 'eight',\n",
       " 'either',\n",
       " 'eleven',\n",
       " 'else',\n",
       " 'elsewhere',\n",
       " 'empty',\n",
       " 'enough',\n",
       " 'etc',\n",
       " 'even',\n",
       " 'ever',\n",
       " 'every',\n",
       " 'everyone',\n",
       " 'everything',\n",
       " 'everywhere',\n",
       " 'except',\n",
       " 'few',\n",
       " 'fifteen',\n",
       " 'fify',\n",
       " 'fill',\n",
       " 'find',\n",
       " 'fire',\n",
       " 'first',\n",
       " 'five',\n",
       " 'for',\n",
       " 'former',\n",
       " 'formerly',\n",
       " 'forty',\n",
       " 'found',\n",
       " 'four',\n",
       " 'from',\n",
       " 'front',\n",
       " 'full',\n",
       " 'further',\n",
       " 'get',\n",
       " 'give',\n",
       " 'go',\n",
       " 'had',\n",
       " 'has',\n",
       " 'hasnt',\n",
       " 'have',\n",
       " 'he',\n",
       " 'hence',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hereafter',\n",
       " 'hereby',\n",
       " 'herein',\n",
       " 'hereupon',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'however',\n",
       " 'hundred',\n",
       " 'i',\n",
       " 'ie',\n",
       " 'if',\n",
       " 'in',\n",
       " 'inc',\n",
       " 'indeed',\n",
       " 'interest',\n",
       " 'into',\n",
       " 'is',\n",
       " 'it',\n",
       " 'its',\n",
       " 'itself',\n",
       " 'keep',\n",
       " 'last',\n",
       " 'latter',\n",
       " 'latterly',\n",
       " 'least',\n",
       " 'less',\n",
       " 'ltd',\n",
       " 'made',\n",
       " 'many',\n",
       " 'may',\n",
       " 'me',\n",
       " 'meanwhile',\n",
       " 'might',\n",
       " 'mill',\n",
       " 'mine',\n",
       " 'more',\n",
       " 'moreover',\n",
       " 'most',\n",
       " 'mostly',\n",
       " 'move',\n",
       " 'much',\n",
       " 'must',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'name',\n",
       " 'namely',\n",
       " 'neither',\n",
       " 'never',\n",
       " 'nevertheless',\n",
       " 'next',\n",
       " 'nine',\n",
       " 'no',\n",
       " 'nobody',\n",
       " 'none',\n",
       " 'noone',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'nothing',\n",
       " 'now',\n",
       " 'nowhere',\n",
       " 'of',\n",
       " 'off',\n",
       " 'often',\n",
       " 'on',\n",
       " 'once',\n",
       " 'one',\n",
       " 'only',\n",
       " 'onto',\n",
       " 'or',\n",
       " 'other',\n",
       " 'others',\n",
       " 'otherwise',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 'part',\n",
       " 'per',\n",
       " 'perhaps',\n",
       " 'please',\n",
       " 'put',\n",
       " 'rather',\n",
       " 're',\n",
       " 'same',\n",
       " 'see',\n",
       " 'seem',\n",
       " 'seemed',\n",
       " 'seeming',\n",
       " 'seems',\n",
       " 'serious',\n",
       " 'several',\n",
       " 'she',\n",
       " 'should',\n",
       " 'show',\n",
       " 'side',\n",
       " 'since',\n",
       " 'sincere',\n",
       " 'six',\n",
       " 'sixty',\n",
       " 'so',\n",
       " 'some',\n",
       " 'somehow',\n",
       " 'someone',\n",
       " 'something',\n",
       " 'sometime',\n",
       " 'sometimes',\n",
       " 'somewhere',\n",
       " 'still',\n",
       " 'such',\n",
       " 'system',\n",
       " 'take',\n",
       " 'ten',\n",
       " 'than',\n",
       " 'that',\n",
       " 'the',\n",
       " 'their',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'thence',\n",
       " 'there',\n",
       " 'thereafter',\n",
       " 'thereby',\n",
       " 'therefore',\n",
       " 'therein',\n",
       " 'thereupon',\n",
       " 'these',\n",
       " 'they',\n",
       " 'thick',\n",
       " 'thin',\n",
       " 'third',\n",
       " 'this',\n",
       " 'those',\n",
       " 'though',\n",
       " 'three',\n",
       " 'through',\n",
       " 'throughout',\n",
       " 'thru',\n",
       " 'thus',\n",
       " 'to',\n",
       " 'together',\n",
       " 'too',\n",
       " 'top',\n",
       " 'toward',\n",
       " 'towards',\n",
       " 'twelve',\n",
       " 'twenty',\n",
       " 'two',\n",
       " 'un',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 'upon',\n",
       " 'us',\n",
       " 'very',\n",
       " 'via',\n",
       " 'was',\n",
       " 'we',\n",
       " 'well',\n",
       " 'were',\n",
       " 'what',\n",
       " 'whatever',\n",
       " 'when',\n",
       " 'whence',\n",
       " 'whenever',\n",
       " 'where',\n",
       " 'whereafter',\n",
       " 'whereas',\n",
       " 'whereby',\n",
       " 'wherein',\n",
       " 'whereupon',\n",
       " 'wherever',\n",
       " 'whether',\n",
       " 'which',\n",
       " 'while',\n",
       " 'whither',\n",
       " 'who',\n",
       " 'whoever',\n",
       " 'whole',\n",
       " 'whom',\n",
       " 'whose',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'within',\n",
       " 'without',\n",
       " 'would',\n",
       " 'yet',\n",
       " 'you',\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "def make_wordlist(filename):\n",
    "    import re\n",
    "    pattern = \"\\w+\"\n",
    "    \n",
    "    file = open(filename, \"r\")\n",
    "    \n",
    "               \n",
    "    \n",
    "    character2 = []\n",
    "    \n",
    "    for line in file:\n",
    "        temp_ord = re.search(pattern, line)\n",
    "        \n",
    "        if temp_ord:\n",
    "            character2.append(temp_ord.group())\n",
    "    file.close()\n",
    "    \n",
    "    character3 = [w.lower() for w in character2]\n",
    "    character3[3] = character3[3].upper()\n",
    "    \n",
    "    return(character3)\n",
    "    \n",
    "  \n",
    "make_wordlist(\"stop_words.txt\")\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.2.3**: Putting the above together allows you to read a file, clean up the words to remove unwanted characters, and count the frequency of words in the text from the file. This results in a sorted list of words. \n",
    "\n",
    "Run the code below to count the frequency of words in `Speech_2019.txt`. This is the speech given by DK Prime Minister Mette Frederiksen at the opening of parliament. Original found [here](http://www.stm.dk/_p_14878.html).\n",
    "\n",
    "Write the resulting list of words frequencies to a new text file with an appropriate name. Have a look at the file, does it seem like all your functions are working as they should? \n",
    "\n",
    "Note: it is ok if you have words that are single letters or numbers. We'll work on improving our data cleaning techniques in later classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Prime',\n",
       " 'The',\n",
       " 'The',\n",
       " 'The',\n",
       " 'The',\n",
       " 'I',\n",
       " 'Because',\n",
       " 'Everyday',\n",
       " 'Past',\n",
       " 'In',\n",
       " 'When',\n",
       " 'In',\n",
       " 'We',\n",
       " 'We',\n",
       " 'I',\n",
       " 'I',\n",
       " 'We',\n",
       " 'And',\n",
       " 'It',\n",
       " 'Just',\n",
       " 'Because',\n",
       " 'Denmark',\n",
       " 'There',\n",
       " 'It',\n",
       " 'Jobs',\n",
       " 'Trust',\n",
       " 'Denmark',\n",
       " 'Do',\n",
       " 'I',\n",
       " 'Or',\n",
       " 'But',\n",
       " 'I',\n",
       " 'But',\n",
       " 'Because',\n",
       " 'The',\n",
       " 'And',\n",
       " 'When',\n",
       " 'Those',\n",
       " 'They',\n",
       " 'I',\n",
       " 'We',\n",
       " 'History',\n",
       " 'In',\n",
       " 'Freedoms',\n",
       " 'And',\n",
       " 'Running',\n",
       " 'There',\n",
       " 'Centralization',\n",
       " 'The',\n",
       " 'An',\n",
       " 'A',\n",
       " 'Apparently',\n",
       " 'Large',\n",
       " 'The',\n",
       " 'Denmark',\n",
       " 'There',\n",
       " 'But',\n",
       " 'A',\n",
       " 'But',\n",
       " 'The',\n",
       " 'If',\n",
       " 'We',\n",
       " 'Therefore',\n",
       " 'The',\n",
       " 'Those',\n",
       " 'I',\n",
       " 'Therefore',\n",
       " 'Instead',\n",
       " 'Greater',\n",
       " 'Today',\n",
       " 'That',\n",
       " 'By',\n",
       " 'And',\n",
       " 'We',\n",
       " 'I',\n",
       " 'I',\n",
       " 'The',\n",
       " 'I',\n",
       " 'On',\n",
       " 'Today',\n",
       " 'Also',\n",
       " 'From',\n",
       " 'Shouldn',\n",
       " 'Because',\n",
       " 'I',\n",
       " 'That',\n",
       " 'I',\n",
       " 'The',\n",
       " 'Midwives',\n",
       " 'I',\n",
       " 'Today',\n",
       " 'You',\n",
       " 'And',\n",
       " 'But',\n",
       " 'The',\n",
       " 'Let',\n",
       " 'And',\n",
       " 'So',\n",
       " 'When',\n",
       " 'So',\n",
       " 'The',\n",
       " 'Therefore',\n",
       " 'In',\n",
       " 'I',\n",
       " 'I',\n",
       " 'I',\n",
       " 'But',\n",
       " 'I',\n",
       " 'Some',\n",
       " 'Everyday',\n",
       " 'Even',\n",
       " 'Even',\n",
       " 'In',\n",
       " 'We',\n",
       " 'But',\n",
       " 'Step',\n",
       " 'Year',\n",
       " 'But',\n",
       " 'We',\n",
       " 'Why',\n",
       " 'The',\n",
       " 'That',\n",
       " 'But',\n",
       " 'And',\n",
       " 'New',\n",
       " 'As',\n",
       " 'Also',\n",
       " 'When',\n",
       " 'A',\n",
       " 'And',\n",
       " 'No',\n",
       " 'It',\n",
       " 'It',\n",
       " 'Of',\n",
       " 'But',\n",
       " 'Welfare',\n",
       " 'We',\n",
       " 'But',\n",
       " 'We',\n",
       " 'Let',\n",
       " 'More',\n",
       " 'We',\n",
       " 'What',\n",
       " 'New',\n",
       " 'But',\n",
       " 'Or',\n",
       " 'Today',\n",
       " 'Many',\n",
       " 'Can',\n",
       " 'The',\n",
       " 'Here',\n",
       " 'I',\n",
       " 'But',\n",
       " 'Someone',\n",
       " 'Meanwhile',\n",
       " 'Employees',\n",
       " 'The',\n",
       " 'Of',\n",
       " 'Here',\n",
       " 'Here',\n",
       " 'Take',\n",
       " 'But',\n",
       " 'The',\n",
       " 'And',\n",
       " 'Here',\n",
       " 'What',\n",
       " 'I',\n",
       " 'Perhaps',\n",
       " 'We',\n",
       " 'But',\n",
       " 'Is',\n",
       " 'Do',\n",
       " 'The',\n",
       " 'Luckily',\n",
       " 'Just',\n",
       " 'Besides',\n",
       " 'We',\n",
       " 'And',\n",
       " 'Legislation',\n",
       " 'If',\n",
       " 'Instead',\n",
       " 'If',\n",
       " 'And',\n",
       " 'We',\n",
       " 'In',\n",
       " 'In',\n",
       " 'In',\n",
       " 'In',\n",
       " 'And',\n",
       " 'Even',\n",
       " 'Because',\n",
       " 'The',\n",
       " 'We',\n",
       " 'Where',\n",
       " 'We',\n",
       " 'The',\n",
       " 'Today',\n",
       " 'It',\n",
       " 'Very',\n",
       " 'Trust',\n",
       " 'Time',\n",
       " 'We',\n",
       " 'Our',\n",
       " 'It',\n",
       " 'Many',\n",
       " 'It',\n",
       " 'But',\n",
       " 'Tomorrow',\n",
       " 'In',\n",
       " 'The',\n",
       " 'Therefore',\n",
       " 'There',\n",
       " 'Immigration',\n",
       " 'For',\n",
       " 'Failed',\n",
       " 'And',\n",
       " 'In',\n",
       " 'Crimes',\n",
       " 'Crime',\n",
       " 'On',\n",
       " 'For',\n",
       " 'And',\n",
       " 'I',\n",
       " 'That',\n",
       " 'That',\n",
       " 'It',\n",
       " 'We',\n",
       " 'And',\n",
       " 'I',\n",
       " 'But',\n",
       " 'Then',\n",
       " 'If',\n",
       " 'The',\n",
       " 'I',\n",
       " 'And',\n",
       " 'And',\n",
       " 'Immigration',\n",
       " 'It',\n",
       " 'It',\n",
       " 'Thousands',\n",
       " 'I',\n",
       " 'And',\n",
       " 'I',\n",
       " 'I',\n",
       " 'Strengthen',\n",
       " 'And',\n",
       " 'Next',\n",
       " 'On',\n",
       " 'Many',\n",
       " 'A',\n",
       " 'Built',\n",
       " 'We',\n",
       " 'Next',\n",
       " 'Not',\n",
       " 'The',\n",
       " 'The',\n",
       " 'And',\n",
       " 'If',\n",
       " 'I',\n",
       " 'A',\n",
       " 'Tax',\n",
       " 'The',\n",
       " 'And',\n",
       " 'Europe',\n",
       " 'Traffickers',\n",
       " 'Our',\n",
       " 'I',\n",
       " 'I',\n",
       " 'And',\n",
       " 'The',\n",
       " 'Because',\n",
       " 'And',\n",
       " 'There',\n",
       " 'In',\n",
       " 'The',\n",
       " 'I',\n",
       " 'We',\n",
       " 'I',\n",
       " 'As',\n",
       " 'The',\n",
       " 'The',\n",
       " 'One',\n",
       " 'The',\n",
       " 'The',\n",
       " 'I',\n",
       " 'Greenland',\n",
       " 'I',\n",
       " 'Vulnerable',\n",
       " 'And',\n",
       " 'Never',\n",
       " 'We',\n",
       " 'If',\n",
       " 'Then',\n",
       " 'If',\n",
       " 'The',\n",
       " 'And',\n",
       " 'But',\n",
       " 'Not',\n",
       " 'In',\n",
       " 'The',\n",
       " 'Children',\n",
       " 'The',\n",
       " 'Committing',\n",
       " 'Retirement',\n",
       " 'And',\n",
       " 'The',\n",
       " 'For',\n",
       " 'We',\n",
       " 'The',\n",
       " 'Alternativet',\n",
       " 'We',\n",
       " 'The',\n",
       " 'It',\n",
       " 'Today',\n",
       " 'But',\n",
       " 'And',\n",
       " 'We',\n",
       " 'Just',\n",
       " 'We',\n",
       " 'And',\n",
       " 'What',\n",
       " 'Let',\n",
       " 'We',\n",
       " 'In',\n",
       " 'Have',\n",
       " 'That',\n",
       " 'A',\n",
       " 'Put',\n",
       " 'That',\n",
       " 'That',\n",
       " 'That',\n",
       " 'The',\n",
       " 'And',\n",
       " 'A',\n",
       " 'We',\n",
       " 'We',\n",
       " 'Caregiving',\n",
       " 'Enthusiasm',\n",
       " 'We',\n",
       " 'I',\n",
       " 'We',\n",
       " 'LONG']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_wordlist(\"Speech_2019.txt\")\n",
    "\n",
    "#Read the file and turn it into a list of words\n",
    "#word_list = make_wordlist(\"Speech_2019.txt\")\n",
    "#remove stop words from the list\n",
    "#word_list = remove_stop_words(word_list, stop_words)\n",
    "#count the frequency of different words\n",
    "#word_dict = word_freq(word_list)\n",
    "#sort the list\n",
    "#sorted_words = sort_freq_dict(word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answer to question 2.2.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 (More) Regular Expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.3.1**: Write a regular expression for a telephone number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Answer to Question 2.3.1* \n",
    "\n",
    "Note this cell is in markdown mode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.3.2**: Write a regular expression for a URL. \n",
    "\n",
    "Note: For this exercise you can use a simple solution that does not account for all possible conditions, but will capture most URLs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Answer to Question 2.3.2* \n",
    "\n",
    "Note this cell is in markdown mode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Reflection\n",
    "**Question 2.4.1**: Write a brief paragraph reflecting on your experience learning programming today. What did you struggle with? What did you enjoy? What surprised you?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answer to question 2.4.1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
